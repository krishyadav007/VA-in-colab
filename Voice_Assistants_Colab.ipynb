{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Voice_Assistants_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishyadav007/VA-in-colab/blob/main/Voice_Assistants_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_imD06zN3llY"
      },
      "source": [
        "# Voice Assistants\n",
        "\n",
        "Pehaps the worlds first working voice assitant working in colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfy95xVZ3llg"
      },
      "source": [
        "# Importing and installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b31JCv-WADvD",
        "outputId": "2f6dfba8-34ac-4e07-8c9e-416bfffdd21d"
      },
      "source": [
        "!pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "!pip install speechRecognition\n",
        "!pip install gTTS\n",
        "from IPython.display import Audio, display, clear_output, Javascript\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "import speech_recognition as sr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     - 3.0 kB 3.2 MB/s\n",
            "\u001b[?25h  Building wheel for Deep-Learning-Colab-Notebook-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting speechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 33 kB/s \n",
            "\u001b[?25hInstalling collected packages: speechRecognition\n",
            "Successfully installed speechRecognition-3.8.1\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.2.3-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTS) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTS) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTS) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTS) (2021.5.30)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxMaEmVB3u-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4c9ebe-415b-4b47-dedb-eabefc5a9d97"
      },
      "source": [
        "!pip install wikipedia\n",
        "!pip install wolframalpha"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=669302d036d2f4695966fa17e35d3065de5e49a289ba03a7aac850968bc3491e\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting wolframalpha\n",
            "  Downloading wolframalpha-5.0.0-py3-none-any.whl (7.5 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting jaraco.context\n",
            "  Downloading jaraco.context-4.0.0-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from wolframalpha) (8.8.0)\n",
            "Installing collected packages: xmltodict, jaraco.context, wolframalpha\n",
            "Successfully installed jaraco.context-4.0.0 wolframalpha-5.0.0 xmltodict-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4-gjfEc3llh"
      },
      "source": [
        "import webbrowser #It is used to open or close your browser\n",
        "import random #It is used to obtain a random value from a group of values\n",
        "import wikipedia #Used to get articles from wikipedia and summarize them if necessary\n",
        "import wolframalpha #Used in the core of the VA\n",
        "import datetime #Used to get the current time\n",
        "import os #For system related functions\n",
        "import sys #For system related functions\n",
        "from gtts import gTTS\n",
        "import librosa\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaS22nPJ3llm"
      },
      "source": [
        "# Setting up recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNn0tL1B3llm"
      },
      "source": [
        "#@title Sound related settings\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "record_seconds =   5#@param {type:\"number\", min:1, max:10, step:1}\n",
        "text_recognized = \"default_text\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPFBF4r33llr"
      },
      "source": [
        "# Initiating the voice assistant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPa_jEc_3lls"
      },
      "source": [
        "def speak(to_speak=\"Default\"):\n",
        "  tts = gTTS(to_speak) #Provide the string to convert to speech\n",
        "  tts.save('out.wav') #save the string converted to speech as a .wav file\n",
        "  sound_file = 'out.wav'\n",
        "  display(Audio(sound_file, autoplay=True))\n",
        "  time.sleep(librosa.get_duration(filename='out.wav'))\n",
        "  return 200 \n",
        "     \n",
        "def _recognize(audio):\n",
        "  # display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  wavfile.write('in.wav', SAMPLE_RATE, (32767*audio).astype(np.int16))\n",
        "  print('\\n')\n",
        "  filename = \"in.wav\"\n",
        "  r = sr.Recognizer()\n",
        "  with sr.AudioFile(filename) as source:\n",
        "      # listen for the data (load audio to memory)\n",
        "      try:\n",
        "        audio_data = r.record(source)\n",
        "        # recognize (convert from speech to text)\n",
        "        text = r.recognize_google(audio_data)\n",
        "        return text\n",
        "      except Exception as e:\n",
        "        print(e)   \n",
        "        print(\"Could you speak more clearly\") \n",
        "        return \"None\"\n",
        "      \n",
        "\n",
        "def _record_audio():\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  text_recognized = _recognize(audio)\n",
        "  print(f\"Users says: {text_recognized}\\n\")\n",
        "  return text_recognized\n",
        "\n",
        "def takeCommand():\n",
        "  button = widgets.Button(description=\"Record Speech\")\n",
        "  return _record_audio()\n",
        "  # button.on_click(_record_audio)\n",
        "  # display(button)\n",
        "\n",
        "def open_web(url):\n",
        "    display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
        "\n",
        "def wishMe():\n",
        "    hour = int(datetime.datetime.now().hour)\n",
        "    if hour>= 0 and hour<12:\n",
        "        speak(\"Good Morning Sir !\")\n",
        "    elif hour>= 12 and hour<18:\n",
        "        speak(\"Good Afternoon Sir !\")  \n",
        "    else:\n",
        "        speak(\"Good Evening Sir !\") \n",
        "    name =(\"Parhsu\")\n",
        "    speak(\"I am your Assistant\")\n",
        "    speak(name)\n",
        "\n",
        "def usrname():\n",
        "    speak(\"What should i call you sir\")\n",
        "    uname = takeCommand()\n",
        "    speak(\"Welcome\")\n",
        "    speak(uname)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vu94_eh3llt"
      },
      "source": [
        "# Setting up Main Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hLx29D43llt"
      },
      "source": [
        "def bot(query=\"\"): \n",
        "    wishMe()\n",
        "    usrname() \n",
        "    while True:\n",
        "        speak(\"How can I help you\")\n",
        "        query = takeCommand().lower()\n",
        "        print(query)\n",
        "        if 'wikipedia' in query:\n",
        "            speak('Searching Wikipedia...')\n",
        "            query = query.replace(\"wikipedia\", \"\")\n",
        "            results = wikipedia.summary(query, sentences = 3)\n",
        "            speak(\"Here is what wikipedia says\")\n",
        "            print(results)\n",
        "            speak(results)\n",
        "            \n",
        "        elif 'open youtube' in query:\n",
        "            speak(\"Yes opening\")\n",
        "            open_web('https://www.youtube.com');\n",
        "            \n",
        "        elif 'open forum' in query:\n",
        "            speak(\"Yes opening \" + str(\"forum.aistudent.community\"))\n",
        "            open_web(\"https://www.forum.aistudent.community\")\n",
        "            \n",
        "        elif 'open google' in query:\n",
        "            speak(\"Yes opening \" + str(\"www.google.co.in\"))\n",
        "            open_web(\"https://www.google.co.in\")\n",
        "            \n",
        "        elif 'open stack overflow' in query:\n",
        "            speak(\"Yes opening \" + str(\"stackoverflow.com\"))\n",
        "            open_web(\"https://www.stackoverflow.com\") \n",
        "            \n",
        "        elif 'how are you' in query:\n",
        "            speak(\"I am fine, Thank you\")\n",
        "            speak(\"How are you, opening \" + str())\n",
        "            \n",
        "        elif 'fine' in query or \"good\" in query:\n",
        "            speak(\"It's good to know that your fine\")\n",
        "            \n",
        "        elif \"change name\" in query:\n",
        "            speak(\"What would you like to call me, Sir \")\n",
        "            name = takeCommand()\n",
        "            speak(\"Thanks for naming me\")\n",
        "            \n",
        "        elif \"what's your name\" in query or \"What is your name\" in query:\n",
        "            speak(\"My friends call me\")\n",
        "            name =(\"Arnold\")\n",
        "            speak(name)\n",
        "            print(\"My friends call me\", name)\n",
        "            \n",
        "        elif 'search' in query or 'play' in query:\n",
        "            query = query.replace(\"search\", \"\")\n",
        "            query = query.replace(\"play\", \"\")         \n",
        "            open_web(query)\n",
        "        \n",
        "        elif \"who are you\" in query:\n",
        "            speak(\"I am your virtual assistant\")\n",
        "            \n",
        "        elif \"where is\" in query:\n",
        "            query = query.replace(\"where is\", \"\")\n",
        "            location = query\n",
        "            speak(\"User asked to Locate\")\n",
        "            speak(location)\n",
        "            open_web(\"https://www.google.com/maps/search/?api=1&\" + location + \"\")\n",
        "\n",
        "        elif \"will you be my friend\" in query:  \n",
        "            speak(\"Sure, why not\")\n",
        "        elif 'exit' in query:\n",
        "            speak(\"Thanks for giving me your time\")\n",
        "            exit()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mBMiLaHuVE7Y",
        "outputId": "a181b536-df74-49bf-df5c-90fbf6ccea68"
      },
      "source": [
        "bot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting recording for 5 seconds...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "      const b2text = blob => new Promise(resolve => {\n",
              "        const reader = new FileReader()\n",
              "        reader.onloadend = e => resolve(e.srcElement.result)\n",
              "        reader.readAsDataURL(blob)\n",
              "      })\n",
              "      var record = time => new Promise(async resolve => {\n",
              "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "        recorder = new MediaRecorder(stream)\n",
              "        chunks = []\n",
              "        recorder.ondataavailable = e => chunks.push(e.data)\n",
              "        recorder.start()\n",
              "        await sleep(time)\n",
              "        recorder.onstop = async ()=>{\n",
              "          blob = new Blob(chunks)\n",
              "          text = await b2text(blob)\n",
              "          resolve(text)\n",
              "        }\n",
              "        recorder.stop()\n",
              "      })\n",
              "      "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}